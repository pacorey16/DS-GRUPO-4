---
title: "R Notebook"
output: html_notebook
---
# 1. Introducción y Objetivos

## 1.1. Contexto del Problema

## 1.2. Objetivos del Estudio

## 1.3. Descripción del Dataset


# 2. Preprocesamiento y Limpieza de Datos
```{r}
library(tidyverse) 
library(corrplot)
```

```{r}
listings <- read.csv("./csv/listings.csv")
```

```{r}
str(listings)
```

## 2.1. Tratamiento de Variables Críticas
```{r}
listings <- listings %>%
  # Limpieza de precio: Quitar $ y ,
  mutate(
    price = as.numeric(gsub("[\\$,]", "", price))
  )

listings_clean <- listings %>%
  # Limpieza de precio: Quitar $ y ,
  mutate(
    price = as.numeric(gsub("[\\$,]", "", price))
  ) %>%
  # Limpieza de baños: Extraer el número del texto "1.5 baths"
  mutate(
    bath_num = case_when(
      str_detect(tolower(bathrooms_text), "half-bath") ~ 0.5,
      TRUE ~ as.numeric(str_extract(bathrooms_text, "\\d+\\.?\\d*"))
    ),
    bath_num = ifelse(is.na(bath_num), 1, bath_num) # Si no hay dato, asumimos 1 baño
  )
```


## 2.2. Gestión de Valores Ausentes
```{r}
listings_clean <- listings_clean %>%
  # Imputar habitaciones y camas usando la mediana segun el tipo de alojamiento
  group_by(room_type) %>%
  mutate(
    bedrooms = ifelse(is.na(bedrooms), median(bedrooms, na.rm=TRUE), bedrooms),
    beds = ifelse(is.na(beds), median(beds, na.rm=TRUE), beds)
  ) %>%
  ungroup() %>%
  
  # Gestionar el numero de reviews vacias 
  mutate(
    reviews_per_month = replace_na(reviews_per_month, 0),
    # Imputamos la media para no perder la fila en modelos predictivos
    review_scores_rating = replace_na(review_scores_rating, mean(review_scores_rating, na.rm=TRUE))
  )
```

## 2.3. Filtrado de Inconsistencias

```{r}
listings_clean <- listings_clean %>%
  # Filtro de precio: eliminamos errores (0€) y mansiones extremas (>2000€)
  filter(price > 10 & price < 2000) %>%
  
  # Filtro geoespacial: eliminamos filas sin coordenadas válidas
  filter(!is.na(latitude) & !is.na(longitude)) %>%
  
  #Filtrar estancias de larga duracion 
  filter(minimum_nights < 365)
```

# 3. Análisis Exploratorio de Datos

## 3.1. Análisis Univariante

###  3.1.1 Distribución del precio 
```{r}
# Gráfico: Histograma
ggplot(listings, aes(x = price)) +
  geom_histogram(binwidth = 10, fill = "#69b3a2", color = "white") +
  theme_minimal() +
  labs(title = "Distribución de Precios (Crudo)", x = "Precio (€)", y = "Frecuencia")

#Ver los extremos
print(paste("Mínimo:", min(listings$price, na.rm = TRUE)))
print(paste("Máximo:", max(listings$price, na.rm = TRUE)))

# Visualizar de nuevo ya limpio
ggplot(listings_clean, aes(x = price)) +
  geom_histogram(binwidth = 10, fill = "steelblue", color = "white") +
  labs(title = "Distribución de Precios (Filtrado 10€ - 2000€)")
```

### 3.1.2 Conteo del tipo de habitacion
```{r}
ggplot(listings, aes(x = room_type, fill = room_type)) +
  geom_bar() +
  geom_text(stat='count', aes(label=..count..), vjust=-0.5) +
  theme_minimal() +
  labs(title = "Conteo por Tipo de Habitación") +
  theme(legend.position = "none")
```

### 3.1.3 Boxplot de noches minimas
```{r}
ggplot(listings, aes(y = minimum_nights)) +
  geom_boxplot(fill = "orange", alpha = 0.5) +
  scale_y_log10() + # Escala logarítmica vital para ver los de 1000 días
  theme_minimal() +
  labs(title = "Detectando Outliers en Noches Mínimas (Escala Log)")

# Ver cuántos superan los 30 días (posibles alquileres de larga estancia)
sum(listings$minimum_nights > 30)
```

## 3.2. Análisis Bivariante
### 3.2.1 Matriz de Correlación
Aquí detectamos la Multicolinealidad 
```{r}
# Seleccionar solo columnas numéricas clave
nums <- listings_clean %>% 
  select(price, accommodates, bedrooms, beds, 
         number_of_reviews, reviews_per_month, availability_365,
         review_scores_rating) %>%
  na.omit() # Correlación no funciona con NAs

# Calcular matriz
M <- cor(nums)

# Graficar Heatmap con corrplot
corrplot(M, method = "color", type = "upper", 
         addCoef.col = "black", # Añade los números
         tl.col = "black", tl.srt = 45, # Color y rotación de texto
         diag = FALSE, # No mostrar la diagonal principal
         title = "Matriz de Correlación")
```

### 3.2.2 Price vs Neighbourhood
```{r}
# Usamos el dataset limpio (sin precios de 9000€)
ggplot(listings_clean, aes(x = reorder(neighbourhood_group_cleansed, price, median), y = price)) +
  geom_boxplot(aes(fill = neighbourhood_group_cleansed), alpha = 0.7) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "none") +
  labs(title = "Precio por Distrito (Ordenado por Mediana)", x = "Distrito")
```

### 3.2.3 Scatterplot Price vs Reviews
```{r}
ggplot(listings_clean, aes(x = reviews_per_month, y = price)) +
  geom_point(alpha = 0.4, color = "darkblue") +
  geom_smooth(method = "lm", color = "red", se = FALSE) + # Línea de tendencia opcional
  theme_minimal() +
  labs(title = "Relación Precio vs Rotación", x = "Reviews por mes", y = "Precio")
```


## 3.3. Análisis Geoespacial
### 3.3.1 Scatterplot latitud vs longitud

```{r}
# Filtramos coordenadas extremas si es necesario (ej: latitud 0)
# Sevilla está aprox en Lat 37.4, Lon -6.0

ggplot(listings_clean, aes(x = longitude, y = latitude, color = price)) +
  geom_point(size = 1, alpha = 0.6) +
  scale_color_viridis_c(option = "magma", direction = -1) + # Colores oscuros para caro
  coord_quickmap() + # Mantiene la proporción del mapa
  theme_void() + # Quita ejes para que parezca un mapa limpio
  labs(title = "Mapa de Precios en Sevilla", color = "Precio (€)")

# La Trampa: Verificar si hay puntos en el mar (0,0)
summary(listings$latitude)
summary(listings$longitude)
```

# 4. Análisis Grupal

## 4.1. Segmentación del Mercado

## 4.2. Determinantes del Precio

## 4.3. El "Efecto Giralda"










